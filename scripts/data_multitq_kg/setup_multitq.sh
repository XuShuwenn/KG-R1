#!/bin/bash
set -e

echo "ğŸš€ MultiTQ Dataset Setup for KG-R1 Training"
echo "============================================="

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
DATA_DIR="$PROJECT_ROOT/data_multitq_kg"
PROCESSED_DIR="$PROJECT_ROOT/data_kg/multitq"
TRAINING_DIR="$PROJECT_ROOT/data_kg/multitq_search_augmented_initial_entities"

echo "ğŸ“ Script directory: $SCRIPT_DIR"
echo "ğŸ“ Raw data directory: $DATA_DIR"
echo "ğŸ“ Processed data directory: $PROCESSED_DIR"
echo "ğŸ“ Training data directory: $TRAINING_DIR"

# Step 1: Download MultiTQ dataset
echo ""
echo "ğŸ“¥ Step 1: Downloading MultiTQ dataset..."
echo "========================================="

if [ -d "$DATA_DIR/MultiTQ" ]; then
    echo "âš ï¸ MultiTQ data already exists, skipping download"
else
    python "$SCRIPT_DIR/download_multitq.py" --output_dir "$DATA_DIR"
    
    if [ $? -ne 0 ]; then
        echo "âŒ Failed to download MultiTQ dataset"
        exit 1
    fi
fi

# Verify download
if [ ! -d "$DATA_DIR/MultiTQ" ]; then
    echo "âŒ MultiTQ directory not found after download"
    exit 1
fi

echo "âœ… MultiTQ dataset ready"

# Step 2: Process dataset for KG-R1 compatibility
echo ""
echo "ğŸ”„ Step 2: Processing dataset for KG-R1 compatibility..."
echo "======================================================="

python "$SCRIPT_DIR/process_multitq.py" \
    --input_dir "$DATA_DIR/MultiTQ" \
    --output_dir "$PROCESSED_DIR"

if [ $? -ne 0 ]; then
    echo "âŒ Failed to process MultiTQ dataset"
    exit 1
fi

# Verify processing
required_files=("entities.txt" "entities_text.txt" "relations.txt")
for file in "${required_files[@]}"; do
    if [ ! -f "$PROCESSED_DIR/$file" ]; then
        echo "âŒ Required file not found: $PROCESSED_DIR/$file"
        exit 1
    fi
done

echo "âœ… Dataset processing completed"

# Step 3: Create search-augmented training data
echo ""
echo "ğŸ¯ Step 3: Creating search-augmented training data..."
echo "===================================================="

python "$SCRIPT_DIR/multitq_search_augmented_initial_entities.py" \
    --input_dir "$PROCESSED_DIR" \
    --output_dir "$TRAINING_DIR"

if [ $? -ne 0 ]; then
    echo "âŒ Failed to create search-augmented training data"
    exit 1
fi

echo "âœ… Search-augmented training data created"

# Step 4: Verify final output
echo ""
echo "ğŸ” Step 4: Verifying final output..."
echo "==================================="

echo "ğŸ“Š Checking processed data files:"
for split in train dev test; do
    split_file="$PROCESSED_DIR/${split}_simple.json"
    if [ -f "$split_file" ]; then
        sample_count=$(wc -l < "$split_file")
        echo "   âœ… ${split}_simple.json: $sample_count samples"
    else
        echo "   âš ï¸ ${split}_simple.json: not found"
    fi
done

echo ""
echo "ğŸ“Š Checking training data files:"
for split in train dev test; do
    parquet_file="$TRAINING_DIR/${split}.parquet"
    if [ -f "$parquet_file" ]; then
        file_size=$(du -h "$parquet_file" | cut -f1)
        echo "   âœ… ${split}.parquet: $file_size"
    else
        echo "   âš ï¸ ${split}.parquet: not found"
    fi
done

# Count entities and relations
if [ -f "$PROCESSED_DIR/entities.txt" ]; then
    entity_count=$(wc -l < "$PROCESSED_DIR/entities.txt")
    echo "   âœ… entities.txt: $entity_count entities"
fi

if [ -f "$PROCESSED_DIR/relations.txt" ]; then
    relation_count=$(wc -l < "$PROCESSED_DIR/relations.txt")
    echo "   âœ… relations.txt: $relation_count relations"
fi

# Step 5: Integration guidance
echo ""
echo "ğŸ‰ MultiTQ dataset setup completed!"
echo "==================================="
echo ""
echo "ğŸ“‹ Available files for KG-R1 training:"
echo "   ğŸ“„ Raw data: $DATA_DIR"
echo "   ğŸ“„ Processed data: $PROCESSED_DIR"
echo "   ğŸ“„ Training data: $TRAINING_DIR"
echo ""
echo "ğŸ¯ Usage in training scripts:"
echo "   data.train_files=\"data_kg/multitq_search_augmented_initial_entities/train.parquet\""
echo "   data.val_files=\"data_kg/multitq_search_augmented_initial_entities/test.parquet\""
echo ""
echo "ğŸ”§ Key features:"
echo "   â€¢ Temporal reasoning with multi-granularity questions"
echo "   â€¢ Search-augmented prompts with initial entity hints"
echo "   â€¢ Compatible with existing KG-R1 training pipeline"
echo "   â€¢ Temporal fact integration for time-sensitive queries"
echo ""
echo "ğŸ“– For more details, see:"
echo "   â€¢ $DATA_DIR/SETUP_SUMMARY.md"
echo "   â€¢ $TRAINING_DIR/DATASET_SUMMARY.md"